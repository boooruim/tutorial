{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLMR\n",
    "\n",
    "In the following examples, we will be taking a look at how Contrastive Learning of Musical Representations (Spijkervet & Burgoyne, 2021) uses self-supervised learning to learn powerful representations for the downstream task of music tagging. \n",
    "\n",
    "<div align=\"center\">\n",
    "<img width=\"700\" src=\"../images/janne/clmr_model.png\"/>\n",
    "</div>\n",
    "\n",
    "In the above figure, we transform a single audio example into two, distinct augmented views by processing it through a set of stochastic audio augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'clmr' already exists and is not an empty directory.\n",
      "Processing ./clmr\n",
      "Requirement already satisfied: simclr in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from clmr==0.1.0) (1.0.2)\n",
      "Requirement already satisfied: torchaudio-augmentations in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from clmr==0.1.0) (0.2.2)\n",
      "Requirement already satisfied: torch in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from clmr==0.1.0) (1.9.1)\n",
      "Requirement already satisfied: torchaudio in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from clmr==0.1.0) (0.9.1)\n",
      "Requirement already satisfied: pytorch-lightning in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from clmr==0.1.0) (1.4.9)\n",
      "Requirement already satisfied: soundfile in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from clmr==0.1.0) (0.10.3.post1)\n",
      "Requirement already satisfied: sklearn in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from clmr==0.1.0) (0.0)\n",
      "Requirement already satisfied: matplotlib in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from clmr==0.1.0) (3.4.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from matplotlib->clmr==0.1.0) (8.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from matplotlib->clmr==0.1.0) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from matplotlib->clmr==0.1.0) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from matplotlib->clmr==0.1.0) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from matplotlib->clmr==0.1.0) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.16 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from matplotlib->clmr==0.1.0) (1.19.0)\n",
      "Requirement already satisfied: six in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->clmr==0.1.0) (1.16.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from pytorch-lightning->clmr==0.1.0) (4.62.3)\n",
      "Requirement already satisfied: torchmetrics>=0.4.0 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from pytorch-lightning->clmr==0.1.0) (0.5.1)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from pytorch-lightning->clmr==0.1.0) (2021.10.0)\n",
      "Requirement already satisfied: pyDeprecate==0.3.1 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from pytorch-lightning->clmr==0.1.0) (0.3.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from pytorch-lightning->clmr==0.1.0) (21.0)\n",
      "Requirement already satisfied: future>=0.17.1 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from pytorch-lightning->clmr==0.1.0) (0.18.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from pytorch-lightning->clmr==0.1.0) (3.10.0.2)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from pytorch-lightning->clmr==0.1.0) (5.4.1)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from pytorch-lightning->clmr==0.1.0) (2.6.0)\n",
      "Requirement already satisfied: requests in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->clmr==0.1.0) (2.26.0)\n",
      "Requirement already satisfied: aiohttp in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->clmr==0.1.0) (3.7.4.post0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->clmr==0.1.0) (1.41.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->clmr==0.1.0) (3.18.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->clmr==0.1.0) (2.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->clmr==0.1.0) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->clmr==0.1.0) (58.0.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->clmr==0.1.0) (3.3.4)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->clmr==0.1.0) (0.37.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->clmr==0.1.0) (0.6.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->clmr==0.1.0) (0.14.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->clmr==0.1.0) (0.4.6)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->clmr==0.1.0) (1.35.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->clmr==0.1.0) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->clmr==0.1.0) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->clmr==0.1.0) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning->clmr==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->clmr==0.1.0) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->clmr==0.1.0) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->clmr==0.1.0) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->clmr==0.1.0) (2.0.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->clmr==0.1.0) (3.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning->clmr==0.1.0) (3.1.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->clmr==0.1.0) (20.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->clmr==0.1.0) (5.2.0)\n",
      "Requirement already satisfied: chardet<5.0,>=2.0 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->clmr==0.1.0) (4.0.0)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->clmr==0.1.0) (3.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->clmr==0.1.0) (1.6.3)\n",
      "Requirement already satisfied: torchvision in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from simclr->clmr==0.1.0) (0.10.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from sklearn->clmr==0.1.0) (1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from scikit-learn->sklearn->clmr==0.1.0) (1.7.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from scikit-learn->sklearn->clmr==0.1.0) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from scikit-learn->sklearn->clmr==0.1.0) (3.0.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from soundfile->clmr==0.1.0) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from cffi>=1.0->soundfile->clmr==0.1.0) (2.20)\n",
      "Requirement already satisfied: julius in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from torchaudio-augmentations->clmr==0.1.0) (0.2.5)\n",
      "Requirement already satisfied: wavaugment in /Users/janne/miniconda3/envs/tutorial/lib/python3.8/site-packages (from torchaudio-augmentations->clmr==0.1.0) (0.2)\n",
      "Building wheels for collected packages: clmr\n",
      "  Building wheel for clmr (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clmr: filename=clmr-0.1.0-py3-none-any.whl size=7258 sha256=11bd135a2d8a72ae95dca3dd62c0b59b639a64bbd879a4250d06dd3a01951213\n",
      "  Stored in directory: /private/var/folders/5n/msbkkqhj2y9bhqwj2gvr70n40000gp/T/pip-ephem-wheel-cache-qq2_mgjk/wheels/47/96/99/4adc73d74f8b28040b7b1a2bbed5172c9ce04a9ba62645fc05\n",
      "Successfully built clmr\n",
      "Installing collected packages: clmr\n",
      "  Attempting uninstall: clmr\n",
      "    Found existing installation: clmr 0.1.0\n",
      "    Uninstalling clmr-0.1.0:\n",
      "      Successfully uninstalled clmr-0.1.0\n",
      "Successfully installed clmr-0.1.0\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/spijkervet/clmr.git\n",
    "!pip3 install clmr/\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"clmr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from torch.utils import data\n",
    "from torchaudio_augmentations import (\n",
    "    RandomResizedCrop,\n",
    "    RandomApply,\n",
    "    PolarityInversion,\n",
    "    Noise,\n",
    "    Gain,\n",
    "    HighLowPass,\n",
    "    Delay,\n",
    "    PitchShift,\n",
    "    Reverb,\n",
    "    Compose,\n",
    ")\n",
    "\n",
    "\n",
    "GTZAN_GENRES = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "\n",
    "\n",
    "class GTZANDataset(data.Dataset):\n",
    "    def __init__(self, data_path, split, num_samples, num_chunks, is_augmentation):\n",
    "        self.data_path =  data_path if data_path else ''\n",
    "        self.split = split\n",
    "        self.num_samples = num_samples\n",
    "        self.num_chunks = num_chunks\n",
    "        self.is_augmentation = is_augmentation\n",
    "        self.genres = GTZAN_GENRES\n",
    "        self._get_song_list()\n",
    "        if is_augmentation:\n",
    "            self._get_augmentations()\n",
    "\n",
    "    def _get_song_list(self):\n",
    "        list_filename = os.path.join(self.data_path, '%s_filtered.txt' % self.split)\n",
    "        with open(list_filename) as f:\n",
    "            lines = f.readlines()\n",
    "        self.song_list = [line.strip() for line in lines]\n",
    "\n",
    "    def _get_augmentations(self):\n",
    "        transforms = [\n",
    "            RandomResizedCrop(n_samples=self.num_samples),\n",
    "            RandomApply([PolarityInversion()], p=0.8),\n",
    "            RandomApply([Noise(min_snr=0.3, max_snr=0.5)], p=0.3),\n",
    "            RandomApply([Gain()], p=0.2),\n",
    "            RandomApply([HighLowPass(sample_rate=22050)], p=0.8),\n",
    "            RandomApply([Delay(sample_rate=22050)], p=0.5),\n",
    "            RandomApply([PitchShift(n_samples=self.num_samples, sample_rate=22050)], p=0.4),\n",
    "            RandomApply([Reverb(sample_rate=22050)], p=0.3),\n",
    "        ]\n",
    "        self.augmentation = Compose(transforms=transforms)\n",
    "\n",
    "    def _adjust_audio_length(self, wav):\n",
    "        if self.split == 'train':\n",
    "            random_index = random.randint(0, len(wav) - self.num_samples - 1)\n",
    "            wav = wav[random_index : random_index + self.num_samples]\n",
    "        else:\n",
    "            hop = (len(wav) - self.num_samples) // self.num_chunks\n",
    "            wav = np.array([wav[i * hop : i * hop + self.num_samples] for i in range(self.num_chunks)])\n",
    "        return wav\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        line = self.song_list[index]\n",
    "\n",
    "        # get genre\n",
    "        genre_name = line.split('/')[0]\n",
    "        genre_index = self.genres.index(genre_name)\n",
    "\n",
    "        # get audio\n",
    "        audio_filename = os.path.join(self.data_path, 'genres', line)\n",
    "        wav, fs = sf.read(audio_filename)\n",
    "\n",
    "        # adjust audio length\n",
    "        wav = self._adjust_audio_length(wav).astype('float32')\n",
    "\n",
    "        # data augmentation\n",
    "        if self.is_augmentation:\n",
    "            wav = self.augmentation(torch.from_numpy(wav).unsqueeze(0)).squeeze(0).numpy()\n",
    "\n",
    "        return wav, genre_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.song_list)\n",
    "\n",
    "def get_dataloader(data_path=None, \n",
    "                   split='train', \n",
    "                   num_samples=22050 * 29, \n",
    "                   num_chunks=1, \n",
    "                   batch_size=16, \n",
    "                   num_workers=0, \n",
    "                   is_augmentation=False):\n",
    "    is_shuffle = True if (split == 'train') else False\n",
    "    batch_size = batch_size if (split == 'train') else (batch_size // num_chunks)\n",
    "    data_loader = data.DataLoader(dataset=GTZANDataset(data_path, \n",
    "                                                       split, \n",
    "                                                       num_samples, \n",
    "                                                       num_chunks, \n",
    "                                                       is_augmentation),\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=is_shuffle,\n",
    "                                  drop_last=False,\n",
    "                                  num_workers=num_workers)\n",
    "    return data_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Audio Data Augmentations\n",
    "- Crop\n",
    "- Filter\n",
    "- Reverb\n",
    "- Polarity\n",
    "- Noise\n",
    "- Pitch\n",
    "- Gain\n",
    "- Delay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from torchaudio_augmentations import (\n",
    "    RandomApply,\n",
    "    ComposeMany,\n",
    "    RandomResizedCrop,\n",
    "    PolarityInversion,\n",
    "    Noise,\n",
    "    Gain,\n",
    "    HighLowPass,\n",
    "    Delay,\n",
    "    PitchShift,\n",
    "    Reverb,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's apply a series of transformations, each applied with an independent probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = [\n",
    "    RandomResizedCrop(n_samples=args.audio_length),\n",
    "    RandomApply([PolarityInversion()], p=args.transforms_polarity),\n",
    "    RandomApply([Noise()], p=args.transforms_noise),\n",
    "    RandomApply([Gain()], p=args.transforms_gain),\n",
    "    RandomApply([HighLowPass(sample_rate=args.sample_rate)], p=args.transforms_filters),\n",
    "    RandomApply([Delay(sample_rate=args.sample_rate)], p=args.transforms_delay),\n",
    "    RandomApply([PitchShift(n_samples=args.audio_length, sample_rate=args.sample_rate)], p=args.transforms_pitch),\n",
    "    RandomApply([Reverb(sample_rate=args.sample_rate)], p=args.transforms_reverb),\n",
    "]\n",
    "num_augmented_samples = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SampleCNN Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SampleCNN(nn.Module):\n",
    "    def __init__(self, strides, supervised, out_dim):\n",
    "        super(SampleCNN, self).__init__()\n",
    "\n",
    "        self.strides = strides\n",
    "        self.supervised = supervised\n",
    "        self.sequential = [\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(1, 128, kernel_size=3, stride=3, padding=0),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        self.hidden = [\n",
    "            [128, 128],\n",
    "            [128, 128],\n",
    "            [128, 256],\n",
    "            [256, 256],\n",
    "            [256, 256],\n",
    "            [256, 256],\n",
    "            [256, 256],\n",
    "            [256, 256],\n",
    "            [256, 512],\n",
    "        ]\n",
    "\n",
    "        assert len(self.hidden) == len(\n",
    "            self.strides\n",
    "        ), \"Number of hidden layers and strides are not equal\"\n",
    "        for stride, (h_in, h_out) in zip(self.strides, self.hidden):\n",
    "            self.sequential.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv1d(h_in, h_out, kernel_size=stride, stride=1, padding=1),\n",
    "                    nn.BatchNorm1d(h_out),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool1d(stride, stride=stride),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # 1 x 512\n",
    "        self.sequential.append(\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm1d(512),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.sequential = nn.Sequential(*self.sequential)\n",
    "\n",
    "        if self.supervised:\n",
    "            self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(512, out_dim)\n",
    "    \n",
    "    def initialize(self, m):\n",
    "        if isinstance(m, (nn.Conv1d)):\n",
    "            # nn.init.xavier_uniform_(m.weight)\n",
    "            # if m.bias is not None:\n",
    "            #     nn.init.xavier_uniform_(m.bias)\n",
    "\n",
    "            nn.init.kaiming_uniform_(m.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.sequential(x)\n",
    "        if self.supervised:\n",
    "            out = self.dropout(out)\n",
    "\n",
    "        out = out.reshape(x.shape[0], out.size(1) * out.size(2))\n",
    "        logit = self.fc(out)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLR(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, projection_dim, n_features):\n",
    "        super(SimCLR, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.n_features = n_features\n",
    "\n",
    "        # Replace the fc layer with an Identity function\n",
    "        self.encoder.fc = Identity()\n",
    "\n",
    "        # We use a MLP with one hidden layer to obtain z_i = g(h_i) = W(2)σ(W(1)h_i) where σ is a ReLU non-linearity.\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(self.n_features, self.n_features, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.n_features, projection_dim, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        h_i = self.encoder(x_i)\n",
    "        h_j = self.encoder(x_j)\n",
    "\n",
    "        z_i = self.projector(h_i)\n",
    "        z_j = self.projector(h_j)\n",
    "        return h_i, h_j, z_i, z_j\n",
    "    \n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss\n",
    "\n",
    "Here, we apply an InfoNCE loss, as proposed by van den Oord et al. (2018) for contrastive learning. InfoNCE loss compares the similarity of our representations $z_i$ and $z_j$, to the similarity of $z_i$ to any other representation in our batch, and applies a softmax over the obtained similarity values. We can write this loss more formally as follows:\n",
    "\n",
    "$$\\ell_{i, j}=-\\log \\frac{\\exp \\left(\\operatorname{sim}\\left(z_{i}, z_{j}\\right) / \\tau\\right)}{\\sum_{k=1}^{2 N} \\mathbb{1}_{[k \\neq i]} \\exp \\left(\\operatorname{sim}\\left(z_{i}, z_{k}\\right) / \\tau\\right)}\n",
    "=-\\operatorname{sim}\\left(z_{i}, z_{j}\\right) / \\tau+\\log \\left[\\sum_{k=1}^{2 N} \\mathbb{1}_{[k \\neq i]} \\exp \\left(\\operatorname{sim}\\left(z_{i}, z_{k}\\right) / \\tau\\right)\\right]$$\n",
    "\n",
    "\n",
    "The similarity metric is the cosine similarity between our representations:\n",
    "\n",
    "$$\\operatorname{sim}\\left(z_{i}, z_{j}\\right)=\\frac{z_{i}^{\\top} \\cdot z_{j}}{\\left\\|z_{i}\\right\\| \\cdot\\left\\|z_{j}\\right\\|}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "\n",
    "\n",
    "class NT_Xent(nn.Module):\n",
    "    def __init__(self, batch_size, temperature, world_size):\n",
    "        super(NT_Xent, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.temperature = temperature\n",
    "        self.world_size = world_size\n",
    "\n",
    "        self.mask = self.mask_correlated_samples(batch_size, world_size)\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "        self.similarity_f = nn.CosineSimilarity(dim=2)\n",
    "\n",
    "    def mask_correlated_samples(self, batch_size, world_size):\n",
    "        N = 2 * batch_size * world_size\n",
    "        mask = torch.ones((N, N), dtype=bool)\n",
    "        mask = mask.fill_diagonal_(0)\n",
    "        for i in range(batch_size * world_size):\n",
    "            mask[i, batch_size * world_size + i] = 0\n",
    "            mask[batch_size * world_size + i, i] = 0\n",
    "        return mask\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "        \"\"\"\n",
    "        We do not sample negative examples explicitly.\n",
    "        Instead, given a positive pair, similar to (Chen et al., 2017), we treat the other 2(N − 1) augmented examples within a minibatch as negative examples.\n",
    "        \"\"\"\n",
    "        N = 2 * self.batch_size * self.world_size\n",
    "\n",
    "        z = torch.cat((z_i, z_j), dim=0)\n",
    "\n",
    "        sim = self.similarity_f(z.unsqueeze(1), z.unsqueeze(0)) / self.temperature\n",
    "\n",
    "        sim_i_j = torch.diag(sim, self.batch_size * self.world_size)\n",
    "        sim_j_i = torch.diag(sim, -self.batch_size * self.world_size)\n",
    "\n",
    "        # We have 2N samples, but with Distributed training every GPU gets N examples too, resulting in: 2xNxN\n",
    "        positive_samples = torch.cat((sim_i_j, sim_j_i), dim=0).reshape(N, 1)\n",
    "        negative_samples = sim[self.mask].reshape(N, -1)\n",
    "\n",
    "        labels = torch.zeros(N).to(positive_samples.device).long()\n",
    "        logits = torch.cat((positive_samples, negative_samples), dim=1)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        loss /= N\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from clmr.models import SampleCNN\n",
    "from clmr.utils import (\n",
    "    load_encoder_checkpoint,\n",
    "    load_finetuner_checkpoint,\n",
    ")\n",
    "\n",
    "batch_size = 48\n",
    "n_classes = 50\n",
    "encoder = SampleCNN(\n",
    "    strides=[3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
    "    supervised=False,\n",
    "    out_dim=n_classes,\n",
    ")\n",
    "\n",
    "n_features = (\n",
    "    encoder.fc.in_features\n",
    ")  # get dimensions of last fully-connected layer\n",
    "\n",
    "model = SimCLR(encoder, projection_dim=64, n_features=n_features)\n",
    "\n",
    "temperature = 0.5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "criterion = NT_Xent(batch_size, temperature, world_size=1)\n",
    "\n",
    "epochs = 100\n",
    "for e in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # for x, _ in train_dataloader:\n",
    "    x_i = torch.randn(batch_size, 1, 59049)\n",
    "    x_j = torch.randn(batch_size, 1, 59049)\n",
    "    \n",
    "    h_i, h_j, z_i, z_j = model(x_i, x_j)\n",
    "    loss = criterion(z_i, z_j)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.model = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5n/msbkkqhj2y9bhqwj2gvr70n40000gp/T/ipykernel_78248/2334478957.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tutorial/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tutorial/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1121\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tutorial/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2822\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2824\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "linear_model = LinearModel(n_features, n_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    linear_model.parameters(),\n",
    "    lr=3e-4,\n",
    ")\n",
    "\n",
    "# freeze SampleCNN encoder weights\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "linear_epochs = 10\n",
    "for e in range(linear_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    x = torch.randn(batch_size, 1, 59049)\n",
    "    y = torch.randn(batch_size).float()\n",
    "    h = encoder(x)\n",
    "    \n",
    "    p = linear_model(h)\n",
    "    \n",
    "    loss = criterion(p, y)\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, xticklabels=GTZAN_GENRES, yticklabels=GTZAN_GENRES, cmap='YlGnBu')\n",
    "print('Accuracy: %.4f' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CLMR pre-training weights to encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-training the encoder takes a while to complete, so let's load the pre-trained weights into our encoder now to speed this up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from clmr.models import SampleCNN\n",
    "from clmr.utils import (\n",
    "    load_encoder_checkpoint,\n",
    "    load_finetuner_checkpoint,\n",
    ")\n",
    "\n",
    "\n",
    "n_classes = 50\n",
    "ENCODER_CHECKPOINT_PATH = \"checkpoint.pt\"\n",
    "\n",
    "encoder = SampleCNN(\n",
    "    strides=[3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
    "    supervised=False,\n",
    "    out_dim=n_classes,\n",
    ")\n",
    "\n",
    "# get dimensions of last fully-connected layer\n",
    "n_features = encoder.fc.in_features\n",
    "\n",
    "# load the enoder weights from a CLMR checkpoint\n",
    "# set the last fc layer to the Identity function, since we attach the\n",
    "# fine-tune head seperately\n",
    "\n",
    "# state_dict = load_encoder_checkpoint(ENCODER_CHECKPOINT_PATH)\n",
    "# encoder.load_state_dict(state_dict)\n",
    "# encoder.fc = Identity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ROC-AUC and PR-AUC scores on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, xticklabels=GTZAN_GENRES, yticklabels=GTZAN_GENRES, cmap='YlGnBu')\n",
    "print('Accuracy: %.4f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "tutorial",
   "language": "python",
   "name": "tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
